{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "701a58a5-893a-4e78-9a37-48258dc0834d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-eba0c0a56dee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munittest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "path = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\n",
    "sys.path.insert(0, path)\n",
    "\n",
    "import unittest\n",
    "import numpy as np \n",
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "\n",
    "from haven import haven_img as hi\n",
    "from haven import haven_utils as hu\n",
    "from haven import haven_results as hr\n",
    "from haven import haven_chk as hc\n",
    "from haven import haven_jobs as hjb\n",
    "\n",
    "\n",
    "class Test(unittest.TestCase):\n",
    "\n",
    "    def test_cartesian_product(self):\n",
    "        # test whether the cartesian product covers all needed variations\n",
    "        exp_dict_1 = {'dataset':'mnist', 'model':'mlp', 'batch_size':1}\n",
    "        exp_dict_2 = {'dataset':'mnist', 'model':'mlp', 'batch_size':5}\n",
    "        exp_dict_3 = {'dataset':'cifar10', 'model':'mlp', 'batch_size':1}\n",
    "        exp_dict_4 = {'dataset':'cifar10', 'model':'mlp', 'batch_size':5}\n",
    "\n",
    "        exp_list = [exp_dict_1, exp_dict_2, exp_dict_3, exp_dict_4]\n",
    "        exp_list_cartesian = hu.cartesian_exp_group({'dataset':['mnist','cifar10'], 'model':'mlp', 'batch_size':[1, 5]})\n",
    "\n",
    "\n",
    "        exp_list_hash = [hu.hash_dict(e) for e in exp_list]\n",
    "        exp_list_cartesian_hash = [hu.hash_dict(e) for e in exp_list_cartesian]\n",
    "\n",
    "        # check if the # experiments is correct\n",
    "        assert(len(exp_list_cartesian_hash) == len(exp_list_hash))\n",
    "\n",
    "        # check that the hashes in the cartesian are all there\n",
    "        for h in exp_list_hash:\n",
    "            assert(h in exp_list_cartesian_hash)\n",
    "\n",
    "        # check that every hash is unique\n",
    "        assert(len(exp_list_cartesian_hash) == len(np.unique(exp_list_cartesian_hash)))\n",
    "\n",
    "    def test_hash(self):\n",
    "        # test whether hashing works for nested dicts \n",
    "        exp_dict_1 = {'model':{'name':'mlp', 'n_layers':30}, 'dataset':'mnist', 'batch_size':1}\n",
    "        exp_dict_2 = {'dataset':'mnist', 'batch_size':1, 'model':{'name':'mlp', 'n_layers':30}}\n",
    "        exp_dict_3 = {'dataset':'mnist', 'batch_size':1, 'model':{'name':'mlp'}}\n",
    "\n",
    "        assert(hu.hash_dict(exp_dict_1) == hu.hash_dict(exp_dict_2))\n",
    "        assert(hu.hash_dict(exp_dict_1) != hu.hash_dict(exp_dict_3))\n",
    "\n",
    "    def test_checkpoint(self):\n",
    "        savedir_base = '.results'\n",
    "        # create exp folder\n",
    "        exp_dict = {'model':{'name':'mlp', 'n_layers':30}, 'dataset':'mnist', 'batch_size':1}\n",
    "        savedir = os.path.join(savedir_base, hu.hash_dict(exp_dict))\n",
    "        hu.save_json(os.path.join(savedir, \"exp_dict.json\"), exp_dict)\n",
    "        hu.torch_save(os.path.join(savedir, \"model.pth\"), torch.zeros(10))\n",
    "        hu.torch_load(os.path.join(savedir, \"model.pth\"))\n",
    "        hc.load_checkpoint(exp_dict, savedir_base, fname='model.pth')\n",
    "        assert(os.path.exists(savedir))\n",
    "\n",
    "        # delete exp folder\n",
    "        hc.delete_experiment(savedir)\n",
    "        assert(not os.path.exists(savedir))\n",
    "\n",
    "        # check backup folder\n",
    "        os.rmdir(savedir_base)\n",
    "\n",
    "    def test_get_score_lists(self):\n",
    "        # save a score_list\n",
    "        savedir_base = '.tmp'\n",
    "        exp_dict = {'model':{'name':'mlp', 'n_layers':30}, \n",
    "                    'dataset':'mnist', 'batch_size':1}\n",
    "        score_list = [{'epoch': 0, 'acc':0.5}, {'epoch': 0, 'acc':0.9}]\n",
    "\n",
    "        hu.save_pkl(os.path.join(savedir_base, hu.hash_dict(exp_dict),\n",
    "                     'score_list.pkl'), score_list)\n",
    "        hu.save_json(os.path.join(savedir_base, hu.hash_dict(exp_dict),\n",
    "                     'exp_dict.json'), exp_dict)\n",
    "        # check if score_list can be loaded and viewed in pandas\n",
    "        exp_list = hu.get_exp_list(savedir_base=savedir_base)\n",
    "        \n",
    "        score_lists = hr.get_score_lists(exp_list, savedir_base=savedir_base)\n",
    "        assert(score_lists[0][0]['acc'] == 0.5)\n",
    "        assert(score_lists[0][1]['acc'] == 0.9)\n",
    "\n",
    "        shutil.rmtree(savedir_base)\n",
    "\n",
    "    def test_get_score_df(self):\n",
    "        # save a score_list\n",
    "        savedir_base = '.tmp'\n",
    "        exp_dict = {'model':{'name':'mlp', 'n_layers':30}, \n",
    "                    'dataset':'mnist', 'batch_size':1}\n",
    "        exp_dict2 = {'model':{'name':'mlp2', 'n_layers':30}, \n",
    "                    'dataset':'mnist', 'batch_size':1}\n",
    "\n",
    "        score_list = [{'epoch': 0, 'acc':0.5}, {'epoch': 0, 'acc':0.9}]\n",
    "\n",
    "        hu.save_pkl(os.path.join(savedir_base, hu.hash_dict(exp_dict),\n",
    "                     'score_list.pkl'), score_list)\n",
    "                     \n",
    "        hu.save_json(os.path.join(savedir_base, hu.hash_dict(exp_dict),\n",
    "                     'exp_dict.json'), exp_dict)\n",
    "\n",
    "        hu.save_json(os.path.join(savedir_base, hu.hash_dict(exp_dict2),\n",
    "                     'exp_dict.json'), exp_dict)\n",
    "        # check if score_list can be loaded and viewed in pandas\n",
    "        exp_list = hu.get_exp_list(savedir_base=savedir_base)\n",
    "        score_df = hr.get_score_df(exp_list, savedir_base=savedir_base)\n",
    "        \n",
    "        assert(np.array(score_df['dataset'])[0].strip(\"'\") == 'mnist')\n",
    "\n",
    "        shutil.rmtree('.tmp')\n",
    "\n",
    "    def test_get_images(self):\n",
    "        # save a score_list\n",
    "        hi.points_on_image([3,2], [3,2], np.ones((100,100, 3)), \n",
    "                        radius=3, c_list=[0, 1])\n",
    "\n",
    "\n",
    "    def test_get_plot(self):\n",
    "        # save a score_list\n",
    "        savedir_base = '.tmp'\n",
    "        exp_dict = {'model':{'name':'mlp', 'n_layers':30}, \n",
    "                    'dataset':'mnist', 'batch_size':1}\n",
    "        score_list = [{'epoch': 0, 'acc':0.5}, {'epoch': 1, 'acc':0.9}]\n",
    "\n",
    "        hu.save_pkl(os.path.join(savedir_base, hu.hash_dict(exp_dict),\n",
    "                     'score_list.pkl'), score_list)\n",
    "        hu.save_json(os.path.join(savedir_base, hu.hash_dict(exp_dict),\n",
    "                     'exp_dict.json'), exp_dict)\n",
    "        # check if score_list can be loaded and viewed in pandas\n",
    "        exp_list = hu.get_exp_list(savedir_base=savedir_base)\n",
    "        \n",
    "        fig, axis = hr.get_plot(exp_list,\n",
    "             savedir_base=savedir_base,\n",
    "             filterby_list=[({'model':{'name':'mlp'}},\n",
    "                             {'style':{'color':'red'}})],\n",
    "             x_metric='epoch',\n",
    "             y_metric='acc')\n",
    "        # fig, axis = hr.get_plot(exp_list,\n",
    "        #      savedir_base=savedir_base,\n",
    "        #      x_metric='epoch',\n",
    "        #      y_metric='acc',\n",
    "        #      mode='pretty_plot')\n",
    "        fig, axis = hr.get_plot(exp_list,\n",
    "             savedir_base=savedir_base,\n",
    "             x_metric='epoch',\n",
    "             y_metric='acc',\n",
    "             mode='bar')\n",
    "        fig.savefig(os.path.join('.tmp', \n",
    "                        'test.png'))\n",
    "\n",
    "        shutil.rmtree('.tmp')\n",
    "\n",
    "    def test_get_result_manager(self):\n",
    "        # save a score_list\n",
    "        savedir_base = '.tmp_plots'\n",
    "        if os.path.exists(savedir_base):\n",
    "            shutil.rmtree(savedir_base)\n",
    "        exp_dict = {'model':{'name':'mlp', 'n_layers':30}, \n",
    "                    'dataset':'mnist', 'batch_size':1}\n",
    "        score_list = [{'epoch': 0, 'acc':0.5}, {'epoch': 1, 'acc':0.9}]\n",
    "\n",
    "        hu.save_pkl(os.path.join(savedir_base, hu.hash_dict(exp_dict),\n",
    "                     'score_list.pkl'), score_list)\n",
    "        hu.save_json(os.path.join(savedir_base, hu.hash_dict(exp_dict),\n",
    "                     'exp_dict.json'), exp_dict)\n",
    "\n",
    "        exp_dict = {'model':{'name':'mlp', 'n_layers':30}, \n",
    "                    'dataset':'cifar10', 'batch_size':1}\n",
    "        score_list = [{'epoch': 0, 'acc':0.25}, {'epoch': 1, 'acc':1.24}, {'epoch': 2, 'acc':1.5}]\n",
    "\n",
    "        hu.save_pkl(os.path.join(savedir_base, hu.hash_dict(exp_dict),\n",
    "                     'score_list.pkl'), score_list)\n",
    "        hu.save_json(os.path.join(savedir_base, hu.hash_dict(exp_dict),\n",
    "                     'exp_dict.json'), exp_dict)\n",
    "\n",
    "        exp_dict = {'model':{'name':'lenet', 'n_layers':30}, \n",
    "                    'dataset':'cifar10', 'batch_size':1}\n",
    "        score_list = [{'epoch': 0, 'acc':0.35}, {'epoch': 1, 'acc':1.2}, {'epoch': 2, 'acc':1.3}]\n",
    "\n",
    "        hu.save_pkl(os.path.join(savedir_base, hu.hash_dict(exp_dict),\n",
    "                     'score_list.pkl'), score_list)\n",
    "        hu.save_json(os.path.join(savedir_base, hu.hash_dict(exp_dict),\n",
    "                     'exp_dict.json'), exp_dict)\n",
    "                     \n",
    "        exp_dict = {'model':{'name':'lenet', 'n_layers':30}, \n",
    "                    'dataset':'cifar10', 'batch_size':5}\n",
    "        score_list = [{'epoch': 0, 'acc':0.15}, {'epoch': 1, 'acc':1.21}, {'epoch': 2, 'acc':1.7}]\n",
    "\n",
    "        hu.save_pkl(os.path.join(savedir_base, hu.hash_dict(exp_dict),\n",
    "                     'score_list.pkl'), score_list)\n",
    "        hu.save_json(os.path.join(savedir_base, hu.hash_dict(exp_dict),\n",
    "                     'exp_dict.json'), exp_dict)\n",
    "\n",
    "        rm = hr.ResultManager(savedir_base=savedir_base)\n",
    "        \n",
    "        # assert(len(rm.exp_groups) == 2)\n",
    "        # for exp_list in rm.exp_groups:\n",
    "        #     assert(exp_list[0]['dataset'] in ['mnist', 'cifar10'])\n",
    "        rm.get_exp_list_df()\n",
    "        rm.get_score_df(avg_across='dataset')\n",
    "        rm.get_score_df(avg_across='dataset', add_prefix=True)\n",
    "        rm.get_score_df()\n",
    "        rm.get_score_lists()\n",
    "        rm.get_images()\n",
    "        table = rm.get_score_table()\n",
    "        table = rm.get_exp_table()\n",
    "        \n",
    "        fig_list = rm.get_plot(x_metric='epoch', y_metric='acc', title_list=['dataset'], legend_list=['model'])\n",
    "        for i, fig in enumerate(fig_list):\n",
    "            fig.savefig(os.path.join(savedir_base, '%d.png' % i))\n",
    "        \n",
    "\n",
    "        order = 'groups_by_metrics'\n",
    "        fig_list = rm.get_plot_all(order=order, x_metric='epoch', y_metric_list=['acc', 'epoch'], title_list=['dataset'], \n",
    "                              legend_list=['model'], \n",
    "                              groupby_list=['dataset'],\n",
    "                              log_metric_list=['acc'],\n",
    "                              map_title_list=[{'mnist':'MNIST'}, {'cifar10':'CIFAR-10'}],\n",
    "                              map_xlabel_list=[{'epoch':'EPOCHS'}],\n",
    "                              map_ylabel_list=[{'acc':'Score'}],\n",
    "                              ylim_list=[[(0.5, 0.8),(0.5, 0.8)],\n",
    "                                         [(0.5, 0.8),(0.5, 0.8)]])\n",
    "\n",
    "        for i, fig in enumerate(fig_list):\n",
    "            fig.savefig(os.path.join(savedir_base, '%s_%d.png' % (order, i)))\n",
    "        \n",
    "        order = 'metrics_by_groups'\n",
    "        fig_list = rm.get_plot_all(order=order, x_metric='epoch', y_metric_list=['acc', 'epoch'], title_list=['dataset'], \n",
    "                              legend_list=['model'], avg_across='batch_size')\n",
    "        for i, fig in enumerate(fig_list):\n",
    "            fig.savefig(os.path.join(savedir_base, '%s_%d.png' % (order, i)))\n",
    "\n",
    "        # shutil.rmtree(savedir_base)\n",
    "\n",
    "    def test_filter_exp_list(self):\n",
    "        exp_list = hu.cartesian_exp_group({'dataset':['imagenet',\n",
    "            'mnist','cifar10'], \n",
    "                        'model':'mlp', 'batch_size':[1, 5]})\n",
    "        \n",
    "        exp_list1 = hu.filter_exp_list(exp_list, \n",
    "                            filterby_list=[{'dataset': 'mnist'}])\n",
    "\n",
    "        exp_list2 = hu.filter_exp_list(exp_list, \n",
    "                            filterby_list=[\n",
    "                                            [{'dataset':'mnist'}]\n",
    "                                           ])\n",
    "\n",
    "        exp_list = hu.filter_exp_list(exp_list, \n",
    "                            filterby_list=[{'dataset':'mnist'},\n",
    "                                            {'dataset':'cifar10'}])\n",
    "        visited = []\n",
    "        for exp_dict in exp_list:\n",
    "            assert(exp_dict['dataset'] in ['mnist', 'cifar10'])\n",
    "            visited += [exp_dict['dataset']]\n",
    "\n",
    "        assert('mnist' in visited)\n",
    "        assert('cifar10' in visited)\n",
    "\n",
    "\n",
    "    def test_group_exp_list(self):\n",
    "        exp_list = hu.cartesian_exp_group({'dataset':['imagenet',\n",
    "            'mnist','cifar10'], \n",
    "                        'model':'mlp', 'batch_size':[1, 5], 'mode':{'fset':1}})\n",
    "\n",
    "        list_of_exp_list = hu.group_exp_list(exp_list,\n",
    "                             groupby_list=['dataset', ['mode','fset']])\n",
    "\n",
    "        list_of_exp_list = hu.group_exp_list(exp_list,\n",
    "                             groupby_list='dataset')\n",
    "        for exp_list in list_of_exp_list:\n",
    "            assert(len(set([exp_dict['dataset'] for exp_dict in exp_list])) \n",
    "                        == 1)\n",
    "\n",
    "\n",
    "    def test_get_best_exp_dict(self):\n",
    "        savedir_base = '.tmp'\n",
    "        exp_dict_1 = {'model':{'name':'mlp', 'n_layers':30}, \n",
    "                    'dataset':'mnist', 'batch_size':1}\n",
    "        score_list = [{'epoch': 0, 'acc':0.5}, {'epoch': 1, 'acc':0.9}]\n",
    "\n",
    "       \n",
    "        hu.save_pkl(os.path.join(savedir_base, hu.hash_dict(exp_dict_1),\n",
    "                     'score_list.pkl'), score_list)\n",
    "\n",
    "        exp_dict_2 = {'model':{'name':'mlp', 'n_layers':35}, \n",
    "                    'dataset':'mnist', 'batch_size':1}\n",
    "        score_list = [{'epoch': 0, 'acc':0.6}, {'epoch': 1, 'acc':1.9}]\n",
    "\n",
    "       \n",
    "        hu.save_pkl(os.path.join(savedir_base, hu.hash_dict(exp_dict_2),\n",
    "                     'score_list.pkl'), score_list)\n",
    "\n",
    "        best_exp_list = hu.filter_exp_list([exp_dict_1, exp_dict_2], savedir_base=savedir_base,\n",
    "                            filterby_list=[({'model.name':'mlp'}, \n",
    "                                    {'best':{'avg_across':'run',\n",
    "                                              'metric':'acc', \n",
    "                                              'metric_agg':'max'}}\n",
    "                                        )])\n",
    "        assert len(best_exp_list) == 1\n",
    "        assert best_exp_list[0]['model']['n_layers'] == 35\n",
    "\n",
    "        best_exp_list = hu.filter_exp_list([exp_dict_1, exp_dict_2], savedir_base=savedir_base,\n",
    "                            filterby_list=[({'model.name':'mlp'}, \n",
    "                                    {'best':{'avg_across':'run',\n",
    "                                              'metric':'acc', \n",
    "                                              'metric_agg':'min'}}\n",
    "                                        )])\n",
    "        assert best_exp_list[0]['model']['n_layers'] == 30                                \n",
    "        # exp 2\n",
    "        exp_dict_2 = {'model':{'name':'mlp2', 'n_layers':30}, \n",
    "                    'dataset':'mnist', 'batch_size':1, 'run':0}\n",
    "        score_list = [{'epoch': 0, 'acc':1.5}, {'epoch': 1, 'acc':1.8}]\n",
    "\n",
    "        hu.save_pkl(os.path.join(savedir_base, hu.hash_dict(exp_dict_2),\n",
    "                     'score_list.pkl'), score_list)\n",
    "        # exp 3\n",
    "        exp_dict_3 = {'model':{'name':'mlp2', 'n_layers':30}, \n",
    "                    'dataset':'mnist', 'batch_size':1, 'run':1}\n",
    "        score_list = [{'epoch': 0, 'acc':1.5}, {'epoch': 1, 'acc':1.3}]\n",
    "\n",
    "        hu.save_pkl(os.path.join(savedir_base, hu.hash_dict(exp_dict_3),\n",
    "                     'score_list.pkl'), score_list)\n",
    "\n",
    "\n",
    "        exp_list = [exp_dict_1, exp_dict_2, exp_dict_3]\n",
    "        best_exp_dict = hu.get_best_exp_dict(exp_list, \n",
    "                            savedir_base=savedir_base, metric='acc', \n",
    "                            avg_across='run',\n",
    "                            metric_agg='max',\n",
    "                            )\n",
    "\n",
    "        assert(best_exp_dict['model']['name'] == 'mlp2')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
